# NKIA AI 조직 미션 문서

**문서 버전**: v0.2
**작성일**: 2026-02-02
**작성**: Claude (AI Assistant)
**검토**: AI 조직장 (예정)

---

## Executive Summary

AI 시대가 도래하면서 SW 업체의 생존 방식이 근본적으로 바뀌고 있다. 바이브 코딩(Vibe Coding)으로 비개발자도 코드를 작성하고, Salesforce·Oracle 같은 거대 SaaS 기업마저 흔들리는 시대다.

이 시대에 살아남는 SW 기업은 "기능을 파는 회사"가 아니라 **"결과에 대한 책임을 파는 회사"**다.

NKIA AI 조직은 이 전환의 핵심 엔진으로서, 엔키아가 "AI 시대에도 신뢰받는 회사"가 되도록 만드는 것을 미션으로 한다.

---

## 1. 시대 인식: 왜 지금 AI 조직인가?

### 1.1 SW 업체 생존 위기

| 위협 요소 | 설명 |
|----------|------|
| **Vibe Coding 시대** | 비개발자가 AI로 코딩하는 세상. 코드 자체의 가치 하락 |
| **SaaS 기업의 위기** | Salesforce, Oracle 등 기업용 SW 거인들의 성장 정체 |
| **레거시 모니터링 시장** | 성장 없는 시장에서 브레인즈/와치텍과 3파전 |
| **AI의 빠른 진화** | 기존 제품 기능이 AI로 대체될 가능성 |

### 1.2 망하는 SW vs 살아남는 SW

| 망하는 SW 기업 | 살아남는 SW 기업 |
|--------------|----------------|
| "기능"을 파는 회사 | "결과에 대한 책임"을 파는 회사 |
| 코드로 복제 가능한 것 | 도메인 + 신뢰 + 관계로 복제 불가능한 것 |
| AI가 대체할 수 있는 영역 | AI가 대체해도 "누가 책임지냐"가 남는 영역 |
| 제품을 납품하고 끝 | 운영의 책임까지 함께 가져가는 파트너 |

### 1.3 핵심 통찰

> **AI가 코드를 민주화해도, "그 코드가 장애를 일으키면 누가 책임지냐"는 질문은 사라지지 않는다.**

IT 운영에서 자동화된 판단이 늘어날수록, 오히려 **Accountability(책임 소재)**와 **Assurance(보증)**의 가치는 더 커진다.

---

## 2. NKIA의 생존 방향

### 2.1 기존 미션과의 연결

NKIA 미션문서(LEAP FORWARD)의 핵심:
> *"기술을 만드는 회사가 아닌, 신뢰를 인수하는 회사"*

이 방향은 정확하다. AI 조직은 이것을 **실현하는 핵심 엔진**이 되어야 한다.

### 2.2 엔키아가 가야 할 방향

```
"IT 운영의 판단을 AI가 하든 사람이 하든,
 그 판단의 결과에 대한 Accountability를 보증하는 플랫폼"
```

- EMS로 장애를 감지하든, AI가 자동으로 감지하든 → **"왜 이 판단을 했는지" 설명 가능**
- ITSM으로 티켓을 처리하든, AI가 자동 처리하든 → **"책임 추적 가능한 구조"**
- 자동화가 실패했을 때 → **"누가, 왜, 어떻게" 명확한 Audit Trail**

---

## 3. AI 조직 미션

### 3.1 미션 선언문

```
┌─────────────────────────────────────────────────────────────────┐
│                                                                 │
│   AI 시대의 IT 운영에서                                          │
│   판단의 자동화는 가속되지만,                                     │
│   책임의 소재는 더 명확해져야 한다.                                │
│                                                                 │
│   AI 조직은 엔키아 제품 전체에                                    │
│   AI 기반 Assurance Layer를 구축하여                             │
│   고객이 AI에게 판단을 맡기더라도                                  │
│   그 결과를 신뢰할 수 있게 만든다.                                 │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 3.2 미션 한 줄 정의

> **"AI가 판단하는 시대, 그 판단을 보증하는 것이 AI 조직의 정체성이다."**

### 3.3 우리가 아닌 것 (What We Are NOT)

| 피해야 할 정체성 | 이유 |
|----------------|------|
| "AI 기능 개발팀" | 기존 제품에 ChatGPT 연동하는 수준은 경쟁력 없음 |
| "연구만 하는 R&D" | 제품과 분리된 연구는 사업 기여도 낮음 |
| "트렌드 추종 조직" | AI 트렌드 쫓아다니면 정체성 없음 |

### 3.4 우리의 정체성 (What We Are)

| 정체성 | 설명 |
|-------|------|
| **AI Assurance Engine** | 엔키아 제품 전체에 "신뢰 가능한 AI 판단" 기능 내재화 |
| **책임 보증 플랫폼** | AI 판단에 대한 설명 가능성(Explainability) 제공 |
| **신제품 AI Core** | 보안 신제품(SIEM 등)의 AI 탐지/대응 핵심 엔진 |
| **전사 AI 역량 허브** | 모든 조직이 AI를 활용할 수 있도록 지원 |

---

## 4. AI 조직의 역할

### 4.1 핵심 역할 4가지

#### Role 1: AI Assurance Engine
- 기존 EMS/ITSM/ITAM 제품에 AI 기반 판단 기능 내재화
- 단순 자동화가 아닌, **"왜 이 판단을 했는지" 설명 가능한 AI**
- 이상 탐지, 근본 원인 분석, 예측 등에 신뢰도 지표 제공

#### Role 2: AIOps + Accountability
- IT 운영 자동화에서 **책임 추적 가능한 구조** 설계
- 자동화 판단의 Audit Trail 제공
- 장애 발생 시 "AI 판단 → 조치 → 결과" 전 과정 추적

#### Role 3: 보안 신제품 AI Core
- 2026년 SIEM 등 보안 신제품의 AI 탐지 엔진 개발
- 위협 탐지, 이상 행위 분석, 자동 대응의 핵심 로직
- 보안 영역에서도 "왜 이것을 위협으로 판단했는가" 설명 가능

#### Role 4: 전사 AI 내재화 지원
- 다른 조직(연구소, 사업본부)의 AI 활용 지원
- AI 도구/방법론 표준화
- 개발자들의 AI 활용 역량 강화 (Vibe Coding 등)

### 4.2 역할 우선순위

```
[1순위] 기존 제품 AI Assurance - 빠른 가치 증명 (Quick Win)
[2순위] 보안 신제품 AI Core - 신사업 핵심 경쟁력
[3순위] 전사 AI 내재화 - 조직 전체 역량 강화
```

---

## 5. AI 조직과 기존 조직의 관계

### 5.1 협업 모델 개요

```
                    ┌─────────────┐
                    │  AI 조직    │
                    │ (Assurance  │
                    │   Engine)   │
                    └──────┬──────┘
                           │
           ┌───────────────┼───────────────┐
           │               │               │
           ▼               ▼               ▼
    ┌─────────────┐ ┌─────────────┐ ┌─────────────┐
    │ NKIA 연구소 │ │  사업본부   │ │ 보안신제품  │
    │ (EMS 제품)  │ │ (ITSM/ITAM) │ │  (SIEM 등)  │
    └─────────────┘ └─────────────┘ └─────────────┘
```

### 5.2 AI 조직의 포지션

| 관계 | 설명 |
|-----|------|
| **vs 연구소** | AI 조직이 AI 엔진/모델 제공, 연구소가 제품에 통합 |
| **vs 사업본부** | AI 조직이 ITSM/ITAM AI 기능 핵심 로직 제공 |
| **vs 신제품팀** | AI 조직이 보안 신제품의 AI Core 담당 |

### 5.3 권한과 책임

- **AI 조직 권한**: AI 관련 기술 의사결정, AI 표준/가이드 수립
- **AI 조직 책임**: AI 기능의 성능/신뢰도, 전사 AI 역량 수준

---

## 6. 구체적 협업 사례

### 6.1 사례 1: 시계열 이상감지 (AI 컨테이너)

```
┌─────────────────────────────────────────────────────────────────┐
│                        Polestar10 제품                          │
│  ┌──────────────┐    ┌──────────────┐    ┌──────────────┐      │
│  │   수집기     │───▶│   AI 서버    │───▶│   대시보드   │      │
│  │  (메트릭)    │    │  (컨테이너)  │    │   (알람)     │      │
│  └──────────────┘    └──────────────┘    └──────────────┘      │
│        ▲                    ▲                   ▲              │
│        │                    │                   │              │
│   제품조직 담당         AI조직 담당          제품조직 담당       │
└─────────────────────────────────────────────────────────────────┘
```

| 구분 | AI 조직 | 제품 개발 조직 (연구소) |
|-----|--------|----------------------|
| **모델** | 이상탐지 알고리즘 개발/학습/튜닝 | - |
| **API 스펙** | 공동 정의 | 공동 정의 |
| **AI 컨테이너** | 컨테이너 이미지 빌드, 배포 패키지 | - |
| **컨테이너 연동** | - | 제품에 컨테이너 통합, 오케스트레이션 |
| **데이터 파이프라인** | 입력 데이터 전처리 스펙 정의 | 수집기 → AI 서버 데이터 전달 구현 |
| **결과 처리** | 이상탐지 결과 포맷 정의 | 알람/대시보드 UI 구현 |
| **성능 튜닝** | 모델 정확도, 오탐률 개선 | 처리 속도, 리소스 최적화 |
| **고객 대응** | 모델 관련 문의 (왜 이상으로 판단?) | 제품 설치/운영 문의 |

### 6.2 사례 2: LLM Chat 기능 (GPU 서버)

```
┌─────────────────────────────────────────────────────────────────┐
│                        Polestar10 제품                          │
│  ┌──────────────┐         API          ┌──────────────┐        │
│  │   Chat UI    │◀───────────────────▶│  GPU 서버    │        │
│  │  (프론트)    │                      │  (LLM 탑재)  │        │
│  └──────────────┘                      └──────────────┘        │
│        ▲                                      ▲                │
│        │                                      │                │
│   제품조직 담당                           AI조직 담당            │
└─────────────────────────────────────────────────────────────────┘
```

| 구분 | AI 조직 | 제품 개발 조직 |
|-----|--------|--------------|
| **LLM 선정/운영** | 모델 선정, 파인튜닝, 프롬프트 엔지니어링 | - |
| **GPU 서버** | 서버 구성, LLM 서빙 인프라 (vLLM 등) | - |
| **API 스펙** | API 엔드포인트 설계, 응답 포맷 정의 | 공동 리뷰 |
| **API 연동** | - | Chat UI에서 API 호출 구현 |
| **Chat UI** | - | 프론트엔드 UI 개발 |
| **컨텍스트 주입** | RAG 파이프라인, 제품 도메인 지식 구축 | 제품 데이터 제공 (매뉴얼, 로그 등) |
| **응답 품질** | 할루시네이션 방지, 답변 품질 개선 | 사용성 피드백 전달 |
| **보안/권한** | - | 사용자 권한에 따른 접근 제어 |

### 6.3 협업 경계 원칙: "AI 로직 vs 제품 로직"

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   AI 조직 영역                제품 조직 영역             │
│   ─────────────              ─────────────             │
│                                                         │
│   • 모델/알고리즘             • 데이터 수집/저장         │
│   • AI 서빙 인프라            • UI/UX                   │
│   • API 제공 (Producer)       • API 소비 (Consumer)     │
│   • 프롬프트 엔지니어링        • 제품 통합/배포          │
│   • 모델 성능 (정확도)         • 시스템 성능 (속도)      │
│   • "왜 이렇게 판단?" 설명     • "어떻게 보여줄까?" 구현  │
│                                                         │
│              ◀──── API 스펙 공동 정의 ────▶             │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

### 6.4 협업 프로세스

```
1. 기획 단계
   ├─ 제품조직: "이런 AI 기능이 필요해요" (요구사항)
   └─ AI조직: "이렇게 구현 가능합니다" (기술 검토)
        ↓
2. 설계 단계
   └─ 공동: API 스펙 정의, 데이터 포맷 합의
        ↓
3. 개발 단계
   ├─ AI조직: 모델 개발, AI 서버/컨테이너 구현
   └─ 제품조직: 연동 코드, UI 구현
        ↓
4. 통합 테스트
   └─ 공동: 연동 테스트, 성능 테스트
        ↓
5. 운영/개선
   ├─ AI조직: 모델 정확도 모니터링, 재학습
   └─ 제품조직: 사용자 피드백 수집, 전달
```

---

## 7. 엣지 케이스별 협업 가이드

### 7.1 장애/버그 상황

#### Case 1-1: AI가 오탐(False Positive)을 냄
```
상황: 정상인데 이상으로 판단 → 고객 불만
```
| 단계 | 담당 | 액션 |
|-----|-----|------|
| 접수 | 제품조직 | 고객 문의 접수, 로그 수집 |
| 1차 분석 | 제품조직 | 데이터 전달 문제인지 확인 |
| 2차 분석 | **AI조직** | 모델 판단 로직 분석, 원인 파악 |
| 해결 | **AI조직** | 모델 튜닝 또는 임계값 조정 |
| 배포 | 공동 | AI조직이 패치, 제품조직이 고객 배포 |

#### Case 1-2: AI가 미탐(False Negative)을 냄
```
상황: 실제 장애인데 감지 못함 → 심각한 문제
```
| 단계 | 담당 | 액션 |
|-----|-----|------|
| 원인 분석 | **AI조직** | 왜 감지 못했는지 분석 |
| 데이터 검토 | 공동 | 입력 데이터가 충분했는지 확인 |
| 모델 개선 | **AI조직** | 학습 데이터 보강, 모델 재학습 |
| Fallback 검토 | 공동 | Rule 기반 백업 탐지 추가 여부 논의 |

#### Case 1-3: AI 서버/컨테이너 다운
```
상황: AI 컨테이너가 죽음 → 이상탐지 기능 중단
```
| 구분 | 담당 | 책임 |
|-----|-----|------|
| 컨테이너 자체 버그 | **AI조직** | 컨테이너 이미지 수정 |
| 리소스 부족 (OOM 등) | **제품조직** | 배포 환경 리소스 조정 |
| 오케스트레이션 문제 | **제품조직** | K8s/Docker 설정 수정 |
| **Fallback 동작** | 공동 | AI 없이도 기본 모니터링 동작하도록 설계 |

#### Case 1-4: LLM이 할루시네이션 응답
```
상황: Chat이 틀린 정보 제공 → 고객이 잘못된 조치
```
| 단계 | 담당 | 액션 |
|-----|-----|------|
| 원인 분석 | **AI조직** | 프롬프트/RAG 문제인지 확인 |
| 컨텍스트 보강 | **AI조직** | RAG 데이터 보강, 프롬프트 개선 |
| UI 개선 | **제품조직** | "AI 답변은 참고용" 면책 문구 추가 |
| 검증 로직 | 공동 | 중요 조치는 사람 확인 단계 추가 |

---

### 7.2 성능 문제

#### Case 2-1: AI 응답이 너무 느림
```
상황: 이상탐지 결과가 30초 후에 나옴 → 실시간 모니터링 의미 없음
```
| 원인 | 담당 | 해결 |
|-----|-----|------|
| 모델 자체가 무거움 | **AI조직** | 경량 모델로 교체, 모델 최적화 |
| 입력 데이터 너무 많음 | 공동 | 샘플링 전략 협의 |
| 서버 리소스 부족 | **제품조직** | GPU/CPU 스펙 상향 가이드 |
| 네트워크 병목 | **제품조직** | API 호출 최적화, 배치 처리 |

#### Case 2-2: GPU 서버 비용 문제
```
상황: 고객이 GPU 서버 비용 부담 → 도입 거부
```
| 해결책 | 담당 | 설명 |
|--------|-----|------|
| CPU 버전 모델 제공 | **AI조직** | 성능 낮지만 CPU로 동작하는 버전 |
| 클라우드 API 옵션 | **AI조직** | 엔키아 클라우드에서 서빙 (SaaS형) |
| 온프레미스 경량화 | 공동 | 필수 기능만 탑재한 Lite 버전 |

#### Case 2-3: 동시 사용자 폭증
```
상황: Chat 기능에 100명이 동시 접속 → LLM 서버 과부하
```
| 구분 | 담당 | 책임 |
|-----|-----|------|
| Rate Limiting 설계 | **AI조직** | API 레벨 제한 |
| 큐잉 시스템 | **AI조직** | 요청 대기열 관리 |
| UI 피드백 | **제품조직** | "처리 중" 표시, 대기 안내 |
| 스케일링 가이드 | **AI조직** | 사용자 수 별 서버 스펙 가이드 |

---

### 7.3 배포/업데이트

#### Case 3-1: AI 모델만 업데이트 (제품 버전 유지)
```
상황: 모델 정확도 개선 → 제품 재배포 없이 모델만 교체
```
| 단계 | 담당 | 액션 |
|-----|-----|------|
| 모델 패키징 | **AI조직** | 새 모델 버전 패키지 |
| 호환성 테스트 | 공동 | 기존 API 스펙과 호환 확인 |
| 배포 가이드 | **AI조직** | 모델 교체 절차 문서화 |
| 고객 배포 | **제품조직** | 고객사에 모델 패치 적용 |

**원칙**: API 스펙 하위 호환성 유지 → 모델만 교체 가능하도록 설계

#### Case 3-2: API 스펙 변경 필요
```
상황: 새 기능 추가로 API 인터페이스 변경 필요
```
| 단계 | 담당 | 액션 |
|-----|-----|------|
| 스펙 변경 제안 | **AI조직** | 변경 사유, 영향 범위 문서화 |
| 영향도 분석 | **제품조직** | 제품 코드 수정 범위 산정 |
| 버전 전략 | 공동 | v1/v2 병행 운영 or Breaking Change |
| 마이그레이션 | 공동 | 기존 고객 업그레이드 계획 |

#### Case 3-3: 고객사별 다른 모델 버전
```
상황: A고객은 v1.0, B고객은 v2.0 사용 중
```
| 구분 | 담당 | 책임 |
|-----|-----|------|
| 버전 관리 | **AI조직** | 모델 버전별 유지보수 정책 |
| 호환성 매트릭스 | 공동 | 제품 버전 ↔ 모델 버전 호환표 |
| EOL 정책 | 공동 | 구버전 지원 종료 시점 결정 |

---

### 7.4 고객 요구사항

#### Case 4-1: 고객사 데이터로 모델 튜닝 요청
```
상황: "우리 환경에 맞게 학습시켜 달라"
```
| 단계 | 담당 | 액션 |
|-----|-----|------|
| 요건 수집 | **제품조직** | 고객 요구사항 정리 |
| 데이터 수집 | **제품조직** | 고객사 학습 데이터 확보 |
| 튜닝 작업 | **AI조직** | 커스텀 모델 학습 |
| 비용 산정 | 공동 | 커스텀 튜닝 비용 책정 |
| 납품 | **AI조직** | 커스텀 모델 패키지 제공 |

#### Case 4-2: "왜 이렇게 판단했는지 설명해달라"
```
상황: 고객이 AI 판단 근거 요청 (감사/컴플라이언스)
```
| 구분 | 담당 | 책임 |
|-----|-----|------|
| 설명 기능 개발 | **AI조직** | Explainability 기능 (SHAP, Attention 등) |
| UI 표시 | **제품조직** | 판단 근거 시각화 화면 |
| 리포트 생성 | 공동 | 감사용 AI 판단 이력 리포트 |

#### Case 4-3: 특정 기능 OFF 요청
```
상황: "AI 기능 끄고 Rule 기반만 쓰고 싶어요"
```
| 구분 | 담당 | 책임 |
|-----|-----|------|
| 기능 토글 설계 | **제품조직** | AI ON/OFF 설정 UI |
| Fallback 동작 | 공동 | AI 없이도 기본 기능 동작 보장 |
| 라이선스 분리 | 공동 | AI 기능 별도 라이선스 여부 검토 |

---

### 7.5 보안/컴플라이언스

#### Case 5-1: 고객 데이터가 외부로 나가면 안됨
```
상황: 공공기관 - "LLM API 호출 시 데이터 유출 우려"
```
| 해결책 | 담당 | 설명 |
|--------|-----|------|
| 온프레미스 LLM | **AI조직** | 고객사 내부에 LLM 서버 설치 |
| 데이터 마스킹 | 공동 | 민감정보 제거 후 API 호출 |
| 폐쇄망 지원 | **AI조직** | 인터넷 없이 동작하는 버전 |

#### Case 5-2: AI 모델에 대한 보안 취약점
```
상황: Prompt Injection, Model Extraction 공격
```
| 구분 | 담당 | 책임 |
|-----|-----|------|
| 모델 보안 | **AI조직** | Prompt Injection 방어, 입력 검증 |
| API 보안 | 공동 | 인증/인가, Rate Limiting |
| 침투 테스트 | 공동 | AI 기능 대상 보안 테스트 |

#### Case 5-3: 개인정보 학습 이슈
```
상황: 고객 로그에 개인정보 포함 → 학습 데이터로 사용 가능?
```
| 구분 | 담당 | 책임 |
|-----|-----|------|
| 데이터 정책 | **AI조직** | 학습 데이터 익명화 정책 수립 |
| 기술적 조치 | **AI조직** | 개인정보 필터링 파이프라인 |
| 고객 동의 | **제품조직** | 데이터 활용 동의 프로세스 |

---

### 7.6 개발 과정 이슈

#### Case 6-1: AI 조직 일정 지연
```
상황: 모델 개발이 늦어져서 제품 출시 지연
```
| 대응 | 담당 | 액션 |
|-----|-----|------|
| 조기 경보 | **AI조직** | 지연 예상 시 즉시 공유 |
| 대안 협의 | 공동 | MVP 범위 축소, 단계별 출시 |
| Fallback 기능 | **제품조직** | AI 없이도 동작하는 버전 먼저 출시 |

#### Case 6-2: 요구사항 변경
```
상황: "이상탐지 말고 예측도 해줘" (중간에 스코프 확대)
```
| 단계 | 담당 | 액션 |
|-----|-----|------|
| 영향도 분석 | **AI조직** | 추가 개발 범위 산정 |
| 우선순위 협의 | 공동 | 현재 버전 vs 다음 버전 |
| 리소스 조정 | 공동 | 필요시 일정/인력 재조정 |

#### Case 6-3: 테스트 데이터 부족
```
상황: 실제 이상 데이터가 없어서 모델 검증 어려움
```
| 해결책 | 담당 | 설명 |
|--------|-----|------|
| 합성 데이터 | **AI조직** | 이상 패턴 시뮬레이션 데이터 생성 |
| 고객 데이터 협조 | **제품조직** | 기존 고객사 익명화 데이터 확보 |
| 파일럿 운영 | 공동 | 실환경 파일럿으로 데이터 수집 |

---

### 7.7 운영/유지보수

#### Case 7-1: 모델 드리프트 (시간 지나면서 정확도 하락)
```
상황: 6개월 후 오탐률 증가 → 고객 환경이 변했음
```
| 구분 | 담당 | 책임 |
|-----|-----|------|
| 모니터링 | **AI조직** | 모델 성능 지표 모니터링 대시보드 |
| 재학습 파이프라인 | **AI조직** | 주기적 재학습 자동화 |
| 알림 | **AI조직** | 성능 저하 시 알림 |
| 고객 안내 | **제품조직** | 모델 업데이트 안내 |

#### Case 7-2: 고객 문의 대응 (1차/2차 구분)
```
상황: 고객이 AI 관련 문의 → 누가 대응?
```
| 문의 유형 | 1차 대응 | 2차 대응 (에스컬레이션) |
|----------|---------|----------------------|
| 설치/배포 문제 | 제품조직 | - |
| AI 기능 사용법 | 제품조직 | - |
| 오탐/미탐 신고 | 제품조직 (접수) | **AI조직** (분석) |
| 모델 성능 불만 | 제품조직 (접수) | **AI조직** (개선) |
| 커스텀 튜닝 요청 | 제품조직 (접수) | **AI조직** (견적/수행) |

---

## 8. 협업 원칙 요약

### 8.1 책임 경계 원칙

```
┌────────────────────────────────────────────────────────────┐
│                                                            │
│  "API 경계를 기준으로 책임을 나눈다"                          │
│                                                            │
│  ┌─────────────┐         API         ┌─────────────┐      │
│  │  제품 조직   │◀═══════════════════▶│  AI 조직    │      │
│  │             │                      │             │      │
│  │ • API 호출  │                      │ • API 제공  │      │
│  │ • 입력 보장 │                      │ • 출력 보장 │      │
│  │ • UI/UX    │                      │ • 모델 품질 │      │
│  └─────────────┘                      └─────────────┘      │
│                                                            │
│  문제 발생 시:                                              │
│  • API 입력이 스펙대로인데 출력이 이상 → AI 조직 책임        │
│  • API 입력이 스펙과 다름 → 제품 조직 책임                   │
│                                                            │
└────────────────────────────────────────────────────────────┘
```

### 8.2 에스컬레이션 경로

```
고객 문의 → 제품조직 (1차) → AI조직 (2차) → 공동 대응 (3차)
```

### 8.3 핵심 원칙 5가지

| # | 원칙 | 설명 |
|---|-----|------|
| 1 | **API 스펙이 계약** | 스펙 준수 시 상대방 탓 불가 |
| 2 | **Fallback 필수** | AI 장애 시에도 기본 기능 동작 |
| 3 | **버전 호환성** | 모델 업데이트가 제품 재배포 강제하지 않음 |
| 4 | **설명 가능성** | AI 판단에는 항상 근거 제공 |
| 5 | **조기 공유** | 문제/지연 발생 시 즉시 상대 조직에 공유 |

---

## 9. 성공 지표 (KPI 초안)

### 9.1 단기 (1년 내)

| 지표 | 목표 |
|-----|------|
| 기존 제품 AI 기능 출시 | Polestar10에 AI 기반 이상탐지 1개 이상 |
| 보안 신제품 AI 엔진 | SIEM AI 탐지 엔진 PoC 완료 |
| 전사 AI 활용률 | 개발자 50% 이상 AI 도구 활용 |

### 9.2 중기 (2-3년)

| 지표 | 목표 |
|-----|------|
| AI Assurance 차별화 | 경쟁사 대비 "설명 가능한 AI" 포지셔닝 확립 |
| 보안 신제품 매출 | AI 기반 보안 제품 매출 발생 |
| AI 조직 규모 | 10명 이상으로 확대 |

---

## 10. 경영진 보고용 핵심 메시지

### 10.1 왜 AI 조직인가?

> SW 업체의 생존 방식이 바뀌고 있습니다.
> 코드를 만드는 것은 누구나 할 수 있는 시대가 왔습니다.
> 하지만 **"그 코드의 결과를 책임지는 것"**은 여전히 가치 있습니다.
>
> AI 조직은 엔키아가 **"AI 시대에도 신뢰받는 회사"**가 되기 위한 핵심 엔진입니다.

### 10.2 AI 조직의 정체성

> **AI 조직은 '기능 개발팀'이 아닙니다.**
> **AI가 판단하는 시대, 그 판단을 보증하는 것이 우리의 정체성입니다.**

### 10.3 기대 효과

1. **기존 제품 경쟁력 강화**: AI 기반 Assurance로 차별화
2. **신사업 핵심 역량**: 보안 신제품의 AI 경쟁력 확보
3. **조직 전체 역량 강화**: AI 시대에 맞는 일하는 방식 전파

---

## 11. 다음 단계 (To-Do)

- [x] v0.1: 미션 및 정체성 정의
- [x] v0.2: 협업 모델 및 엣지 케이스 정의
- [ ] v0.3: 인력 구조 및 채용 계획
- [ ] v0.4: 1년 로드맵 상세화
- [ ] v0.5: 예산 및 리소스 계획

---

## 변경 이력

| 버전 | 날짜 | 변경 내용 |
|-----|------|----------|
| v0.1 | 2026-02-01 | 초안 작성 (미션, 정체성, 역할 정의) |
| v0.2 | 2026-02-02 | 구체적 협업 사례 추가, 엣지 케이스별 협업 가이드 추가, 협업 원칙 정리 |

---

*이 문서는 AI 조직 미션 수립을 위한 초안이며, 경영진 및 이해관계자와의 논의를 통해 발전시켜 나갈 예정입니다.*
