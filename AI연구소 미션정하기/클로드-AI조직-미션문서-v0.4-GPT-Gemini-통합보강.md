# NKIA AI 조직 미션 문서

**문서 버전**: v0.4 (GPT/Gemini 통합 보강)
**작성일**: 2026-02-02
**작성**: Claude (AI Assistant)
**검토**: AI 조직장 (예정)

---

## v0.4 변경 사항 요약

### 이번 버전에서 추가/보강된 내용

| 변경 항목 | 출처 | 섹션 |
|----------|------|------|
| **조직명 제안 3가지** | Gemini | 3.5 |
| **"하지 않는 일" 정의** | GPT | 4.3 (신규) |
| **운영 원칙 4가지** | GPT | 4.4 (신규) |
| **KPI - "데모 개수 금지" 철학** | GPT | 10.3 (보강) |
| **90일 실행 계획** | GPT | 12 (신규) |
| **Enabler 철학** | Gemini | 4.4, 13 |
| **Dogfooding 원칙** | Gemini | 13 |

### 변경 전후 비교

```
v0.3 구조                          v0.4 구조 (보강)
─────────────                      ─────────────────
1. 시대 인식                        1. 시대 인식
2. NKIA 생존 방향                   2. NKIA 생존 방향
3. AI 조직 미션                     3. AI 조직 미션
                                      + 3.5 조직명 제안 [Gemini]
4. AI 조직 역할                     4. AI 조직 역할
                                      + 4.3 하지 않는 일 [GPT]
                                      + 4.4 운영 원칙 [GPT+Gemini]
5~8. 협업 모델/엣지케이스           5~8. (동일)
9. 인력 구조                        9. 인력 구조
10. KPI                            10. KPI (데모금지 철학 보강) [GPT]
11. 경영진 보고                     11. 경영진 보고
                                   12. 90일 실행 계획 [GPT] (신규)
                                   13. 일하는 방식/문화 [Gemini] (신규)
```

---

## Executive Summary

AI 시대가 도래하면서 SW 업체의 생존 방식이 근본적으로 바뀌고 있다. 바이브 코딩(Vibe Coding)으로 비개발자도 코드를 작성하고, Salesforce·Oracle 같은 거대 SaaS 기업마저 흔들리는 시대다.

이 시대에 살아남는 SW 기업은 "기능을 파는 회사"가 아니라 **"결과에 대한 책임을 파는 회사"**다.

NKIA AI 조직은 이 전환의 핵심 엔진으로서, 엔키아가 "AI 시대에도 신뢰받는 회사"가 되도록 만드는 것을 미션으로 한다.

---

## 1. 시대 인식: 왜 지금 AI 조직인가?

### 1.1 SW 업체 생존 위기

| 위협 요소 | 설명 |
|----------|------|
| **Vibe Coding 시대** | 비개발자가 AI로 코딩하는 세상. 코드 자체의 가치 하락 |
| **SaaS 기업의 위기** | Salesforce, Oracle 등 기업용 SW 거인들의 성장 정체 |
| **레거시 모니터링 시장** | 성장 없는 시장에서 브레인즈/와치텍과 3파전 |
| **AI의 빠른 진화** | 기존 제품 기능이 AI로 대체될 가능성 |

### 1.2 망하는 SW vs 살아남는 SW

| 망하는 SW 기업 | 살아남는 SW 기업 |
|--------------|----------------|
| "기능"을 파는 회사 | "결과에 대한 책임"을 파는 회사 |
| 코드로 복제 가능한 것 | 도메인 + 신뢰 + 관계로 복제 불가능한 것 |
| AI가 대체할 수 있는 영역 | AI가 대체해도 "누가 책임지냐"가 남는 영역 |
| 제품을 납품하고 끝 | 운영의 책임까지 함께 가져가는 파트너 |

### 1.3 핵심 통찰

> **AI가 코드를 민주화해도, "그 코드가 장애를 일으키면 누가 책임지냐"는 질문은 사라지지 않는다.**

IT 운영에서 자동화된 판단이 늘어날수록, 오히려 **Accountability(책임 소재)**와 **Assurance(보증)**의 가치는 더 커진다.

---

## 2. NKIA의 생존 방향

### 2.1 기존 미션과의 연결

NKIA 미션문서(LEAP FORWARD)의 핵심:
> *"기술을 만드는 회사가 아닌, 신뢰를 인수하는 회사"*

이 방향은 정확하다. AI 조직은 이것을 **실현하는 핵심 엔진**이 되어야 한다.

### 2.2 엔키아가 가야 할 방향

```
"IT 운영의 판단을 AI가 하든 사람이 하든,
 그 판단의 결과에 대한 Accountability를 보증하는 플랫폼"
```

- EMS로 장애를 감지하든, AI가 자동으로 감지하든 → **"왜 이 판단을 했는지" 설명 가능**
- ITSM으로 티켓을 처리하든, AI가 자동 처리하든 → **"책임 추적 가능한 구조"**
- 자동화가 실패했을 때 → **"누가, 왜, 어떻게" 명확한 Audit Trail**

---

## 3. AI 조직 미션

### 3.1 미션 선언문

```
┌─────────────────────────────────────────────────────────────────┐
│                                                                 │
│   AI 시대의 IT 운영에서                                          │
│   판단의 자동화는 가속되지만,                                     │
│   책임의 소재는 더 명확해져야 한다.                                │
│                                                                 │
│   AI 조직은 엔키아 제품 전체에                                    │
│   AI 기반 Assurance Layer를 구축하여                             │
│   고객이 AI에게 판단을 맡기더라도                                  │
│   그 결과를 신뢰할 수 있게 만든다.                                 │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 3.2 미션 한 줄 정의

> **"AI 시대에도 사라지지 않는 운영·보안 책임을, NKIA 제품 안에서 '설명 가능하고 통제 가능한 자동화'로 구현하여 고객의 신뢰를 인수한다."**

*(GPT 문서의 표현을 채택하여 보강)*

### 3.3 우리가 아닌 것 (What We Are NOT)

| 피해야 할 정체성 | 이유 |
|----------------|------|
| "AI 기능 개발팀" | 기존 제품에 ChatGPT 연동하는 수준은 경쟁력 없음 |
| "연구만 하는 R&D" | 제품과 분리된 연구는 사업 기여도 낮음 |
| "트렌드 추종 조직" | AI 트렌드 쫓아다니면 정체성 없음 |

### 3.4 우리의 정체성 (What We Are)

| 정체성 | 설명 |
|-------|------|
| **AI Assurance Engine** | 엔키아 제품 전체에 "신뢰 가능한 AI 판단" 기능 내재화 |
| **책임 보증 플랫폼** | AI 판단에 대한 설명 가능성(Explainability) 제공 |
| **신제품 AI Core** | 보안 신제품(SIEM 등)의 AI 탐지/대응 핵심 엔진 |
| **전사 AI 역량 허브** | 모든 조직이 AI를 활용할 수 있도록 지원 |

### 3.5 조직명 제안 [Gemini에서 채택]

> **🆕 v0.4 신규 추가**

단순한 R&D 조직을 넘어 전사적 혁신(Transformation)을 주도한다는 의지를 담아 다음 명칭을 제안합니다.

#### 1안: AX 전략실 (AX Strategy Division) - 추천

- **AX** = AI Transformation
- 'AI 연구'에 국한되지 않고 **'AI 전환'**이라는 전략적 목표 수행
- 타 본부와 협업 시 **전략적 위상** 확보에 유리

#### 2안: AI CoE (AI Center of Excellence)

- 전사의 AI 역량을 결집하는 **중심축(Hub)** 역할 강조
- 가이드 및 인프라 제공자 뉘앙스

#### 3안: AI 연구소 (현행 유지)

- 기존 명칭 유지로 변화 최소화
- 단, "연구"에 국한된 이미지 우려

**권장**: 조직 개편 시 경영진과 1안/2안 중 논의

---

## 4. AI 조직의 역할

### 4.1 핵심 역할 4가지

#### Role 1: AI Assurance Engine
- 기존 EMS/ITSM/ITAM 제품에 AI 기반 판단 기능 내재화
- 단순 자동화가 아닌, **"왜 이 판단을 했는지" 설명 가능한 AI**
- 이상 탐지, 근본 원인 분석, 예측 등에 신뢰도 지표 제공

#### Role 2: AIOps + Accountability
- IT 운영 자동화에서 **책임 추적 가능한 구조** 설계
- 자동화 판단의 Audit Trail 제공
- 장애 발생 시 "AI 판단 → 조치 → 결과" 전 과정 추적

#### Role 3: 보안 신제품 AI Core
- 2026년 SIEM 등 보안 신제품의 AI 탐지 엔진 개발
- 위협 탐지, 이상 행위 분석, 자동 대응의 핵심 로직
- 보안 영역에서도 "왜 이것을 위협으로 판단했는가" 설명 가능

#### Role 4: 전사 AI 내재화 지원
- 다른 조직(연구소, 사업본부)의 AI 활용 지원
- AI 도구/방법론 표준화
- 개발자들의 AI 활용 역량 강화 (Vibe Coding 등)

### 4.2 역할 우선순위

```
[1순위] 기존 제품 AI Assurance - 빠른 가치 증명 (Quick Win)
[2순위] 보안 신제품 AI Core - 신사업 핵심 경쟁력
[3순위] 전사 AI 내재화 - 조직 전체 역량 강화
```

### 4.3 하지 않는 일 (Scope Out) [GPT에서 채택]

> **🆕 v0.4 신규 추가**

AI 조직이 전사에서 소모되지 않기 위한 **명시적 경계선**입니다.

| 하지 않는 일 | 이유 |
|------------|------|
| **재사용 불가능한 1회성 커스터마이징** | 한 고객사만을 위한 AI 기능은 제품화 가치 없음 |
| **KPI 없는 PoC** | 성공 기준 없는 개념검증은 시간 낭비 |
| **데이터/근거 없이 "모델부터" 만들기** | 데이터 확보 → 문제 정의 → 모델 순서 준수 |
| **제품 개발 대행** | AI 조직은 핵심 엔진 제공, 제품 통합은 제품팀과 공동 |
| **논문을 위한 연구** | 고객 가치나 사업 기여 없는 순수 연구 지양 |

**거절 프로세스**:
```
요청 접수 → 재사용 가능성 검토 → KPI 정의 가능? → 데이터 있음?
    ↓              ↓                  ↓              ↓
  (Yes)         (No면 거절)        (No면 거절)    (No면 데이터 확보 먼저)
```

### 4.4 운영 원칙 [GPT + Gemini 통합]

> **🆕 v0.4 신규 추가**

| # | 원칙 | 출처 | 설명 |
|---|-----|------|------|
| 1 | **책임 있는 자동화** | GPT | 자동화는 통제(승인/롤백)와 감사추적이 동반될 때만 제품화 |
| 2 | **제품 우선** | GPT | 데모가 아니라 고객 운영지표가 개선되어야 함 |
| 3 | **재사용 우선** | GPT | 한 번 만든 것은 최소 2개 제품/모듈에서 재사용 가능해야 함 |
| 4 | **단일 책임** | GPT | AI 품질/안전/비용의 기준은 AI 조직이 "표준"을 갖고 관리 |
| 5 | **Enabler, Not Doer** | Gemini | 물고기를 잡아주지 않고, 낚싯대를 만들어 쥐여줌 |
| 6 | **Dogfooding** | Gemini | 외부에 팔기 전에 내부에서 먼저 검증 |

---

## 5. AI 조직과 기존 조직의 관계

### 5.1 협업 모델 개요

```
                    ┌─────────────┐
                    │  AI 조직    │
                    │ (Assurance  │
                    │   Engine)   │
                    └──────┬──────┘
                           │
           ┌───────────────┼───────────────┐
           │               │               │
           ▼               ▼               ▼
    ┌─────────────┐ ┌─────────────┐ ┌─────────────┐
    │ NKIA 연구소 │ │  사업본부   │ │ 보안신제품  │
    │ (EMS 제품)  │ │ (ITSM/ITAM) │ │  (SIEM 등)  │
    └─────────────┘ └─────────────┘ └─────────────┘
```

### 5.2 AI 조직의 포지션

| 관계 | 설명 |
|-----|------|
| **vs 연구소** | AI 조직이 AI 엔진/모델 제공, 연구소가 제품에 통합 |
| **vs 사업본부** | AI 조직이 ITSM/ITAM AI 기능 핵심 로직 제공 |
| **vs 신제품팀** | AI 조직이 보안 신제품의 AI Core 담당 |

### 5.3 권한과 책임

- **AI 조직 권한**: AI 관련 기술 의사결정, AI 표준/가이드 수립
- **AI 조직 책임**: AI 기능의 성능/신뢰도, 전사 AI 역량 수준

---

## 6. 구체적 협업 사례

### 6.1 사례 1: 시계열 이상감지 (AI 컨테이너)

```
┌─────────────────────────────────────────────────────────────────┐
│                        Polestar10 제품                          │
│  ┌──────────────┐    ┌──────────────┐    ┌──────────────┐      │
│  │   수집기     │───▶│   AI 서버    │───▶│   대시보드   │      │
│  │  (메트릭)    │    │  (컨테이너)  │    │   (알람)     │      │
│  └──────────────┘    └──────────────┘    └──────────────┘      │
│        ▲                    ▲                   ▲              │
│        │                    │                   │              │
│   제품조직 담당         AI조직 담당          제품조직 담당       │
└─────────────────────────────────────────────────────────────────┘
```

| 구분 | AI 조직 | 제품 개발 조직 (연구소) |
|-----|--------|----------------------|
| **모델** | 이상탐지 알고리즘 개발/학습/튜닝 | - |
| **API 스펙** | 공동 정의 | 공동 정의 |
| **AI 컨테이너** | 컨테이너 이미지 빌드, 배포 패키지 | - |
| **컨테이너 연동** | - | 제품에 컨테이너 통합, 오케스트레이션 |
| **데이터 파이프라인** | 입력 데이터 전처리 스펙 정의 | 수집기 → AI 서버 데이터 전달 구현 |
| **결과 처리** | 이상탐지 결과 포맷 정의 | 알람/대시보드 UI 구현 |
| **성능 튜닝** | 모델 정확도, 오탐률 개선 | 처리 속도, 리소스 최적화 |
| **고객 대응** | 모델 관련 문의 (왜 이상으로 판단?) | 제품 설치/운영 문의 |

### 6.2 사례 2: LLM Chat 기능 (GPU 서버)

```
┌─────────────────────────────────────────────────────────────────┐
│                        Polestar10 제품                          │
│  ┌──────────────┐         API          ┌──────────────┐        │
│  │   Chat UI    │◀───────────────────▶│  GPU 서버    │        │
│  │  (프론트)    │                      │  (LLM 탑재)  │        │
│  └──────────────┘                      └──────────────┘        │
│        ▲                                      ▲                │
│        │                                      │                │
│   제품조직 담당                           AI조직 담당            │
└─────────────────────────────────────────────────────────────────┘
```

| 구분 | AI 조직 | 제품 개발 조직 |
|-----|--------|--------------|
| **LLM 선정/운영** | 모델 선정, 파인튜닝, 프롬프트 엔지니어링 | - |
| **GPU 서버** | 서버 구성, LLM 서빙 인프라 (vLLM 등) | - |
| **API 스펙** | API 엔드포인트 설계, 응답 포맷 정의 | 공동 리뷰 |
| **API 연동** | - | Chat UI에서 API 호출 구현 |
| **Chat UI** | - | 프론트엔드 UI 개발 |
| **컨텍스트 주입** | RAG 파이프라인, 제품 도메인 지식 구축 | 제품 데이터 제공 (매뉴얼, 로그 등) |
| **응답 품질** | 할루시네이션 방지, 답변 품질 개선 | 사용성 피드백 전달 |
| **보안/권한** | - | 사용자 권한에 따른 접근 제어 |

### 6.3 협업 경계 원칙: "AI 로직 vs 제품 로직"

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   AI 조직 영역                제품 조직 영역             │
│   ─────────────              ─────────────             │
│                                                         │
│   • 모델/알고리즘             • 데이터 수집/저장         │
│   • AI 서빙 인프라            • UI/UX                   │
│   • API 제공 (Producer)       • API 소비 (Consumer)     │
│   • 프롬프트 엔지니어링        • 제품 통합/배포          │
│   • 모델 성능 (정확도)         • 시스템 성능 (속도)      │
│   • "왜 이렇게 판단?" 설명     • "어떻게 보여줄까?" 구현  │
│                                                         │
│              ◀──── API 스펙 공동 정의 ────▶             │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

### 6.4 협업 프로세스

```
1. 기획 단계
   ├─ 제품조직: "이런 AI 기능이 필요해요" (요구사항)
   └─ AI조직: "이렇게 구현 가능합니다" (기술 검토)
        ↓
2. 설계 단계
   └─ 공동: API 스펙 정의, 데이터 포맷 합의
        ↓
3. 개발 단계
   ├─ AI조직: 모델 개발, AI 서버/컨테이너 구현
   └─ 제품조직: 연동 코드, UI 구현
        ↓
4. 통합 테스트
   └─ 공동: 연동 테스트, 성능 테스트
        ↓
5. 운영/개선
   ├─ AI조직: 모델 정확도 모니터링, 재학습
   └─ 제품조직: 사용자 피드백 수집, 전달
```

---

## 7. 엣지 케이스별 협업 가이드

### 7.1 장애/버그 상황

#### Case 1-1: AI가 오탐(False Positive)을 냄
| 단계 | 담당 | 액션 |
|-----|-----|------|
| 접수 | 제품조직 | 고객 문의 접수, 로그 수집 |
| 1차 분석 | 제품조직 | 데이터 전달 문제인지 확인 |
| 2차 분석 | **AI조직** | 모델 판단 로직 분석, 원인 파악 |
| 해결 | **AI조직** | 모델 튜닝 또는 임계값 조정 |
| 배포 | 공동 | AI조직이 패치, 제품조직이 고객 배포 |

#### Case 1-2: AI가 미탐(False Negative)을 냄
| 단계 | 담당 | 액션 |
|-----|-----|------|
| 원인 분석 | **AI조직** | 왜 감지 못했는지 분석 |
| 데이터 검토 | 공동 | 입력 데이터가 충분했는지 확인 |
| 모델 개선 | **AI조직** | 학습 데이터 보강, 모델 재학습 |
| Fallback 검토 | 공동 | Rule 기반 백업 탐지 추가 여부 논의 |

#### Case 1-3: AI 서버/컨테이너 다운
| 구분 | 담당 | 책임 |
|-----|-----|------|
| 컨테이너 자체 버그 | **AI조직** | 컨테이너 이미지 수정 |
| 리소스 부족 (OOM 등) | **제품조직** | 배포 환경 리소스 조정 |
| 오케스트레이션 문제 | **제품조직** | K8s/Docker 설정 수정 |
| **Fallback 동작** | 공동 | AI 없이도 기본 모니터링 동작하도록 설계 |

#### Case 1-4: LLM이 할루시네이션 응답
| 단계 | 담당 | 액션 |
|-----|-----|------|
| 원인 분석 | **AI조직** | 프롬프트/RAG 문제인지 확인 |
| 컨텍스트 보강 | **AI조직** | RAG 데이터 보강, 프롬프트 개선 |
| UI 개선 | **제품조직** | "AI 답변은 참고용" 면책 문구 추가 |
| 검증 로직 | 공동 | 중요 조치는 사람 확인 단계 추가 |

### 7.2 성능 문제

*(v0.3과 동일 - 생략)*

### 7.3 배포/업데이트

*(v0.3과 동일 - 생략)*

### 7.4 고객 요구사항

*(v0.3과 동일 - 생략)*

### 7.5 보안/컴플라이언스

*(v0.3과 동일 - 생략)*

### 7.6 개발 과정 이슈

*(v0.3과 동일 - 생략)*

### 7.7 운영/유지보수

*(v0.3과 동일 - 생략)*

---

## 8. 협업 원칙 요약

### 8.1 책임 경계 원칙

```
┌────────────────────────────────────────────────────────────┐
│                                                            │
│  "API 경계를 기준으로 책임을 나눈다"                          │
│                                                            │
│  ┌─────────────┐         API         ┌─────────────┐      │
│  │  제품 조직   │◀═══════════════════▶│  AI 조직    │      │
│  │             │                      │             │      │
│  │ • API 호출  │                      │ • API 제공  │      │
│  │ • 입력 보장 │                      │ • 출력 보장 │      │
│  │ • UI/UX    │                      │ • 모델 품질 │      │
│  └─────────────┘                      └─────────────┘      │
│                                                            │
│  문제 발생 시:                                              │
│  • API 입력이 스펙대로인데 출력이 이상 → AI 조직 책임        │
│  • API 입력이 스펙과 다름 → 제품 조직 책임                   │
│                                                            │
└────────────────────────────────────────────────────────────┘
```

### 8.2 에스컬레이션 경로

```
고객 문의 → 제품조직 (1차) → AI조직 (2차) → 공동 대응 (3차)
```

### 8.3 핵심 원칙 5가지

| # | 원칙 | 설명 |
|---|-----|------|
| 1 | **API 스펙이 계약** | 스펙 준수 시 상대방 탓 불가 |
| 2 | **Fallback 필수** | AI 장애 시에도 기본 기능 동작 |
| 3 | **버전 호환성** | 모델 업데이트가 제품 재배포 강제하지 않음 |
| 4 | **설명 가능성** | AI 판단에는 항상 근거 제공 |
| 5 | **조기 공유** | 문제/지연 발생 시 즉시 상대 조직에 공유 |

---

## 9. 인력 구조 및 채용 계획

### 9.1 현재 → 목표 조직 구조

```
현재 (5명)              →    2년 후 (12~15명)
─────────────                ─────────────────
AI Engineer 3명              ML팀 (4~5명)
풀스택 2명                   Platform팀 (3~4명)
+ 채용중 2명                 LLM/GenAI팀 (3~4명)
```

### 9.2 단계별 채용 계획

| Phase | 시점 | 인원 | 핵심 채용 |
|-------|-----|------|----------|
| 1 | ~6개월 | 5→7~8명 | MLOps Engineer |
| 2 | 6개월~1년 | 8→10~11명 | LLM Engineer, Security AI, Data Engineer |
| 3 | 1~2년 | 11→12~15명 | 시니어 ML, RAG, Infra |

### 9.3 포지션별 요약

| 포지션 | 역할 | 우선순위 |
|-------|------|---------|
| ML Engineer (시니어) | 모델 설계, 팀 리드 | Phase 3 |
| ML Engineer (미들) | 모델 개발, 학습 | Phase 1 |
| LLM Engineer | LLM, 프롬프트, RAG | Phase 2 |
| MLOps Engineer | 배포, 모니터링 | Phase 1 |
| Security AI Engineer | SIEM AI 엔진 | Phase 2 |
| Backend Developer | AI API 서버 | Phase 1 |

*(상세 JD는 v0.3 참조)*

---

## 10. 성공 지표 (KPI)

### 10.1 KPI 철학 [GPT에서 채택]

> **🆕 v0.4 보강**

```
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  ❌ "데모 개수"로 측정하지 않는다                             │
│                                                             │
│  AI 조직의 성과는 "데모 몇 개 했다"가 아니라                  │
│  실제 운영/보안 지표 개선으로 측정한다.                       │
│                                                             │
│  ✅ 경보량 감소율                                            │
│  ✅ MTTR(평균 복구시간) 감소                                 │
│  ✅ 오탐률 감소                                              │
│  ✅ 분석가 처리시간 감소                                     │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 10.2 단기 KPI (1년 내)

| 영역 | 지표 | 목표 |
|-----|------|------|
| **운영(Ops)** | Polestar10 AI 이상탐지 출시 | 1개 이상 |
| **운영(Ops)** | 경보량 감소율 | 30% 이상 |
| **보안(Sec)** | SIEM AI 엔진 PoC | 완료 |
| **플랫폼** | 전사 AI 도구 활용률 | 개발자 50% 이상 |
| **인력** | AI 조직 규모 | 7~8명 |

### 10.3 중기 KPI (2-3년)

| 영역 | 지표 | 목표 |
|-----|------|------|
| **운영(Ops)** | MTTR 감소율 | 20% 이상 |
| **보안(Sec)** | 오탐률 감소 | 50% 이상 |
| **보안(Sec)** | AI 기반 보안 제품 매출 | 발생 |
| **플랫폼** | 신규 AI 기능 출시 리드타임 | 30% 단축 |
| **인력** | AI 조직 규모 | 12~15명 |

---

## 11. 경영진 보고용 핵심 메시지

### 11.1 왜 AI 조직인가?

> SW 업체의 생존 방식이 바뀌고 있습니다.
> 코드를 만드는 것은 누구나 할 수 있는 시대가 왔습니다.
> 하지만 **"그 코드의 결과를 책임지는 것"**은 여전히 가치 있습니다.
>
> AI 조직은 엔키아가 **"AI 시대에도 신뢰받는 회사"**가 되기 위한 핵심 엔진입니다.

### 11.2 AI 조직의 정체성

> **AI 조직은 '기능 개발팀'이 아닙니다.**
> **AI가 판단하는 시대, 그 판단을 보증하는 것이 우리의 정체성입니다.**

### 11.3 기대 효과

1. **기존 제품 경쟁력 강화**: AI 기반 Assurance로 차별화
2. **신사업 핵심 역량**: 보안 신제품의 AI 경쟁력 확보
3. **조직 전체 역량 강화**: AI 시대에 맞는 일하는 방식 전파

---

## 12. 90일 실행 계획 [GPT에서 채택]

> **🆕 v0.4 신규 추가**

조직 개편 직후 빠르게 가치를 증명하기 위한 90일 계획입니다.

### D+30: 조직 헌장(Charter) 확정

| 항목 | 산출물 |
|-----|-------|
| 하는 일 / 하지 않는 일 | 본 문서 4.1, 4.3 기반 확정 |
| 전사 요청 접수 방식 | Intake 프로세스 + 우선순위 규칙 |
| AI 품질/안전/비용 표준 | 모델 평가 기준, 보안 체크리스트 |
| 타 조직과 협업 규칙 | API 경계 기반 R&R 합의 |

### D+60: 대표 유즈케이스 1개 제품화 착수

| 항목 | 내용 |
|-----|------|
| 유즈케이스 선정 | 고객 체감 큰 1개 (예: 경보 중복 제거) |
| KPI 먼저 확정 | 예: 경보 30% 감소, 분류 시간 20% 단축 |
| 개발 착수 | KPI 합의 후 개발 시작 |

### D+90: 공통 AI 모듈 1종 전사 제공

| 항목 | 내용 |
|-----|------|
| 대상 | 사건화/요약/추천 중 1개 |
| 형태 | 내부 서비스 또는 SDK |
| 목표 | "AI팀 없이도 제품팀이 붙일 수 있게" |

```
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  D+30          D+60              D+90                       │
│    │            │                  │                        │
│    ▼            ▼                  ▼                        │
│  ┌────┐      ┌─────┐           ┌─────┐                     │
│  │헌장│ ───▶ │제품화│ ────────▶ │공통 │                     │
│  │확정│      │착수 │           │모듈 │                     │
│  └────┘      └─────┘           └─────┘                     │
│                                                             │
│  "우리가 뭘 하는 조직인지"  "실제로 제품에서"  "다른 팀도 쓸 수 있게" │
│  명확히 정의              가치를 증명        확장              │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

---

## 13. 일하는 방식 (Working Principles) [Gemini에서 채택]

> **🆕 v0.4 신규 추가**

### 13.1 Business First (기술보다 가치)

> 우리는 논문을 쓰기 위해 연구하지 않는다.
> 고객의 비용을 줄이거나, 회사의 이익을 늘리는 기술에 우선순위를 둔다.

### 13.2 Be an Enabler, Not a Doer (해주는 것이 아니라, 할 수 있게 돕는다)

> AI 조직의 핵심은 **전파**다.
> 우리는 물고기를 잡아주는 대신, 최첨단 낚싯대(AI Tool)를 만들어 쥐여준다.

**예시**:
- 개발팀을 위한 '레거시 코드 분석 봇'
- 영업팀을 위한 '제안서 초안 생성기'
- 전사를 위한 'AI 도구 사용 가이드'

### 13.3 Show, Don't Tell (말보다 결과물)

> 긴 보고서보다 하나의 작동하는 프로토타입이 더 강력하다.
> 내부 혁신(Dogfooding) 성공 사례로 우리의 가치를 증명한다.

### 13.4 Dogfooding (내부에서 먼저)

> 우리가 개발한 AI 도구를 사내 인프라에 먼저 적용하여 검증한다.
> 외부에 팔기 전에 내부에서 신뢰를 얻어야 한다.

**적용 예시**:
- Polestar10 개발 인프라에 AI 모니터링 적용
- 내부 헬프데스크에 AI 챗봇 적용
- 코드 리뷰에 AI 도구 활용

---

## 14. 다음 단계 (To-Do)

- [x] v0.1: 미션 및 정체성 정의
- [x] v0.2: 협업 모델 및 엣지 케이스 정의
- [x] v0.3: 인력 구조 및 채용 계획
- [x] v0.4: GPT/Gemini 통합 보강 (하지 않는 일, 90일 계획, 운영 원칙, 조직명, 문화)
- [ ] v0.5: 예산 및 리소스 계획
- [ ] v1.0: 최종본 (경영진 리뷰 후)

---

## 변경 이력

| 버전 | 날짜 | 변경 내용 |
|-----|------|----------|
| v0.1 | 2026-02-01 | 초안 작성 (미션, 정체성, 역할 정의) |
| v0.2 | 2026-02-02 | 구체적 협업 사례 추가, 엣지 케이스별 협업 가이드 추가, 협업 원칙 정리 |
| v0.3 | 2026-02-02 | 인력 구조 및 채용 계획 추가 |
| **v0.4** | **2026-02-02** | **GPT/Gemini 문서 비교 분석 후 통합 보강** |
| | | - [GPT] 하지 않는 일 (Scope Out) 정의 추가 |
| | | - [GPT] 운영 원칙 4가지 추가 |
| | | - [GPT] KPI "데모 개수 금지" 철학 반영 |
| | | - [GPT] 90일 실행 계획 추가 |
| | | - [Gemini] 조직명 3가지 제안 추가 |
| | | - [Gemini] Enabler 철학, Dogfooding 원칙 추가 |
| | | - [Gemini] 일하는 방식(Working Principles) 섹션 추가 |

---

*이 문서는 Claude, GPT, Gemini 세 AI의 미션 문서를 비교 분석하여 각각의 장점을 통합한 버전입니다.*
